{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_hog = dlib.get_frontal_face_detector()\n",
    "def detect_hog(img, face_detector):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces in grayscale\n",
    "    # 1 is the number of times to upsample the image (helps to detect smaller faces)\n",
    "    rects = face_detector(img, 1)\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roi(eye, image):\n",
    "    x, y, w, h = cv2.boundingRect(np.array([eye]))\n",
    "    h = w\n",
    "    y = y - h\n",
    "    x = x - w // 2\n",
    "    cv2.rectangle(image, (x, y), (x+(w*2), y+(h*2)), (255,0,0), 2)\n",
    "    roi = image[y:y + (h*2), x:x + (w*2)]\n",
    "    roi = imutils.resize(roi, width=24, inter=cv2.INTER_CUBIC)\n",
    "\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor('facial-landmarks/shape_predictor_68_face_landmarks.dat')\n",
    "def crop_eyes(frame):\n",
    "    # detect the face at grayscale image\n",
    "    rect = detect_hog(frame, face_hog)\n",
    "    \n",
    "    # if the face detector doesn’t detect face\n",
    "    # return None, else if detects more than one faces\n",
    "    # keep the bigger and if it is only one keep one dim\n",
    "    if len(rect) == 0:\n",
    "        return None\n",
    "    elif len(rect) > 1:\n",
    "        face = rect[0]\n",
    "    elif len(rect) == 1:\n",
    "        [face] = rect\n",
    "        \n",
    "    (f_x, f_y, f_w, f_h) = face_utils.rect_to_bb(face)\n",
    "    cv2.rectangle(frame, (f_x, f_y), (f_x + f_w, f_y + f_h), (0, 255, 0), 2) \n",
    "    \n",
    "    # determine the facial landmarks for the face region\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    shape = predictor(gray, face)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "    # grab the indexes of the facial landmarks for the left and right eye, respectively\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS['right_eye']\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS['left_eye']\n",
    "    \n",
    "    # extract the left and right eye indexes\n",
    "    left_eye = shape[lStart:lEnd]\n",
    "    right_eye = shape[rStart:rEnd]\n",
    "    \n",
    "    # get ROI (region of interest) for the eyes\n",
    "    left_eye_image = draw_roi(left_eye, frame)\n",
    "    right_eye_image = draw_roi(right_eye, frame)\n",
    "    \n",
    "    # if it doesn’t detect left or right eye return None\n",
    "    if 0 in left_eye_image.shape or 0 in right_eye_image.shape:\n",
    "        return None\n",
    "\n",
    "    # return left and right eye\n",
    "    cv2.imwrite('temp/temp.png', left_eye_image)\n",
    "    return left_eye_image, right_eye_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_predict(img, model):\n",
    "    # convert to greyscale and scale between 0 and 1\n",
    "    img = np.dot(np.array(img, dtype='float32'), [[0.2989], [0.5870], [0.1140]]) / 255\n",
    "    # keras needs (row, width, height, channel)\n",
    "    # expand to add row dimension\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images, batch_size=10)\n",
    "    return classes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, weight_path):\n",
    "    json_file = open(model_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    # load model architecture\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(weight_path)\n",
    "    # compile the loaded model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_alarm(path):\n",
    "    # play an alarm sound\n",
    "    playsound.playsound(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    counter = 0\n",
    "    alarm_on = False\n",
    "    max_frame = 20\n",
    "\n",
    "    model = load_model('model_test.json', 'weight_test.h5')\n",
    "    \n",
    "    img = cv2.imread('hog.png')\n",
    "    img = imutils.resize(img, width=500)\n",
    "    \n",
    "    left_eye, right_eye = crop_eyes(img)\n",
    "    \n",
    "    state_left = cnn_predict(left_eye, model)\n",
    "    state_right = cnn_predict(right_eye, model)\n",
    "    \n",
    "    if state_left == 0 and state_right == 0:\n",
    "        cv2.putText(img, \"Closed\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "    else:\n",
    "        cv2.putText(img, \"Opened\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Face\", img)\n",
    "    cv2.waitKey(0)\n",
    "    print(img.shape)\n",
    "    \n",
    "    print(state_left, state_right)\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendonhapp/anaconda/envs/py36/lib/python3.6/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
